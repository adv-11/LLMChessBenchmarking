======================================================================
LLM CHESS BENCHMARK - DATA SUMMARY
======================================================================

LEADERBOARD DATA (N=12 models):
 Rank                  Model    Category  Elo  Win%  Draw%  Loss%  Blunder%  Illegal%  AvgTime
    1         o3-mini (High)   Reasoning 1923  68.2   24.1    7.7      12.3       1.2      4.2
    2            DeepSeek-R1   Reasoning 1876  64.8   26.3    8.9      14.8       2.1      5.1
    3             o1-preview   Reasoning 1842  62.4   27.2   10.4      15.6       1.8      6.8
    4                 GPT-4o    Frontier 1790  58.3   28.4   13.3      18.7      12.7      2.1
    5 GPT-3.5-turbo-instruct  Historical 1748  54.2   29.8   16.0      21.4       8.9      1.8
    6      Claude 3.5 Sonnet    Frontier 1624  46.1   32.7   21.2      26.8      18.4      2.3
    7         Gemini 2.0 Pro    Frontier 1587  42.8   34.2   23.0      29.3      22.1      2.7
    8         Llama 3.1 405B Open-Source 1456  35.2   36.8   28.0      34.7      28.6      3.1
    9            GPT-4 Turbo  Historical 1412  31.8   38.1   30.1      37.2      24.3      2.4
   10           Qwen 2.5 72B Open-Source 1368  28.4   39.2   32.4      41.8      32.7      2.9
   11          Claude 3 Opus  Historical 1289  23.7   40.8   35.5      46.3      35.9      2.6
   12        Mistral Large 2 Open-Source 1124  16.2   42.1   41.7      52.8      44.2      2.2

CATEGORY STATISTICS:
   Category  Mean_Elo  SD_Elo  Mean_Win%  Mean_Blunder%  Mean_Illegal%
  Reasoning      1880    41.2       65.1           14.2            1.7
   Frontier      1667   107.3       49.1           24.9           17.7
 Historical      1483   229.8       36.6           35.0           23.0
Open-Source      1316   170.2       26.6           43.1           35.2

PERFORMANCE VS DIFFICULTY:
            Model  SF_Depth_10  SF_Depth_15  SF_Depth_20
   o3-mini (High)         71.3         42.8          8.3
      DeepSeek-R1         67.8         38.6          6.1
       o1-preview         65.2         35.4          4.7
           GPT-4o         61.4         28.7          2.1
Claude 3.5 Sonnet         49.7         18.2          0.8
   Gemini 2.0 Pro         46.3         14.9          0.4

PHASE-SPECIFIC PERFORMANCE:
     Phase  Reasoning  Frontier  Open-Source
   Opening       76.3      62.4         48.7
Middlegame       62.7      48.2         31.9
   Endgame       69.1      56.8         38.2

CENTIPAWN LOSS BY PHASE:
     Phase  Reasoning  Reasoning_SD  Frontier  Frontier_SD  Open-Source  Open-Source_SD
   Opening       28.4          12.1      47.3         18.7         68.2            24.6
Middlegame       52.7          21.4      89.6         31.2        127.4            42.8
   Endgame       35.9          16.8      71.2         26.4         94.7            34.1

KEY FINDINGS:
- Top Model: o3-mini (High) (Elo: 1923)
- Reasoning vs Non-Reasoning Gap: 391 Elo points
- Best Win Rate: 68.2%
- Lowest Blunder Rate: 12.3%
- Lowest Illegal Move Rate: 1.2%

